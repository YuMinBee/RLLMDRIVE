# RLLMDRIVE - Vision-Language Model for Autonomous Driving

μμ¨μ£Όν–‰μ„ μ„ν• Vision-Language λ©€ν‹°λ¨λ‹¬ λ¨λΈ ν”„λ΅μ νΈ

## π“‹ ν”„λ΅μ νΈ κ°μ”

Carla μ‹λ®¬λ μ΄ν„°μ λΉ„μ „ μ •λ³΄λ¥Ό LLMμ΄ μ΄ν•΄ν•  μ μλ„λ΅ ν† ν°ν™”ν•μ—¬, μμ¨μ£Όν–‰ μμ‚¬κ²°μ •μ— ν™μ©ν•λ” Vision-Language λ¨λΈ κ°λ°

## π― λ©ν‘

- Carla μ‹λ®¬λ μ΄μ… μ΄λ―Έμ§€ β†’ ν…μ¤νΈ μ„¤λ… λ³€ν™
- λ„λ΅ μƒν™©, μ¥μ• λ¬Ό, λ‚ μ”¨ λ“± μ¥λ©΄ μ΄ν•΄
- κ°•ν™”ν•™μµκ³Ό μ—°λ™ κ°€λ¥ν• κµ¬μ΅°ν™”λ μ¶λ ¥

## π› οΈ κ°λ° ν™κ²½

### Python & ν¨ν‚¤μ§€
- **Python**: 3.8.10 (Carla, ROS νΈν™μ„±)
- **PyTorch**: 1.12.1+cu116 (CUDA 11.6)
- **Transformers**: 4.46.3
- **κ°€μƒν™κ²½**: venv (`/venv/`)

### μ£Όμ” λΌμ΄λΈλ¬λ¦¬
```
torch==1.12.1
torchvision==0.13.1
transformers==4.46.3
pillow==10.4.0
accelerate==1.0.1
```

## π“‚ ν”„λ΅μ νΈ κµ¬μ΅°

```
RLLMDRIVE/
β”β”€β”€ blip2_model.py          # BLIP-2 Vision-Language λ¨λΈ (λ©”μΈ)
β”β”€β”€ vision_llm_model.py     # CLIP + GPT-2 μ»¤μ¤ν…€ λ¨λΈ (μ‹¤ν—μ©)
β”β”€β”€ test_vision_llm.py      # λ”λ―Έ μ΄λ―Έμ§€ ν…μ¤νΈ
β”β”€β”€ test_carla_image.py     # Carla μ΄λ―Έμ§€ ν…μ¤νΈ
β”β”€β”€ main.py                 # λ©”μΈ μ§„μ…μ  (ν–¥ν›„ μ‚¬μ©)
β”β”€β”€ requirements.txt        # ν¨ν‚¤μ§€ μμ΅΄μ„±
β”β”€β”€ git_push.sh            # Git μλ™ ν‘Έμ‹ μ¤ν¬λ¦½νΈ
β””β”€β”€ README.md              # ν”„λ΅μ νΈ λ¬Έμ„
```

## π€ μ§„ν–‰ μƒν™©

### β… μ™„λ£λ μ‘μ—…

1. **κ°λ° ν™κ²½ κµ¬μ¶•**
   - Python 3.8 κ°€μƒν™κ²½ μƒμ„±
   - PyTorch 1.12.1 μ„¤μΉ (Python 3.8 νΈν™)
   - μμ΅΄μ„± λ¬Έμ  ν•΄κ²° (sympy, typing-extensions λ“±)

2. **λ¨λΈ κµ¬ν„**
   - **CLIP + GPT-2 μ»¤μ¤ν…€ λ¨λΈ** (`vision_llm_model.py`)
     - Vision Encoder: CLIP ViT-Base
     - Projector: 2-layer MLP (CLIP β†’ GPT-2 μ°¨μ› λ³€ν™)
     - LLM: GPT-2
     - κµ¬μ΅° μ΄ν•΄μ©, Projector λ―Έν•™μµ μƒνƒ
   
   - **BLIP-2 λ¨λΈ** (`blip2_model.py`) β­ **ν„μ¬ λ©”μΈ**
     - μ‚¬μ „ ν•™μµλ Vision-Language λ¨λΈ
     - Salesforce/blip2-opt-2.7b (~10GB)
     - μ‹¤μ  μ΄λ―Έμ§€ μ΄ν•΄ κ°€λ¥
     - GPU μλ™ κ°μ§€ (CUDA/CPU)

3. **ν…μ¤νΈ ν™κ²½**
   - λ”λ―Έ μ΄λ―Έμ§€ μƒμ„± λ° ν…μ¤νΈ
   - Carla μ΄λ―Έμ§€ ν…μ¤νΈ μ¤ν¬λ¦½νΈ
   - λ‹¤μ–‘ν• ν”„λ΅¬ν”„νΈ μ‹¤ν— μ¤€λΉ„

4. **Git λ²„μ „ κ΄€λ¦¬**
   - GitHub μ €μ¥μ† μ—°λ™ μ™„λ£
   - μλ™ ν‘Έμ‹ μ¤ν¬λ¦½νΈ (`./git_push.sh`)

### π”„ μ§„ν–‰ μ¤‘

- **BLIP-2 λ¨λΈ λ‹¤μ΄λ΅λ“** (~10GB, μΈν„°λ„· μ†λ„μ— λ”°λΌ μ‹κ°„ μ†μ”)
- Carla μ΄λ―Έμ§€λ΅ μ²« ν…μ¤νΈ λ€κΈ° μ¤‘

### π“ λ‹¤μ λ‹¨κ³„

1. **μ¦‰μ‹ μ‹¤ν–‰ κ°€λ¥**
   - [ ] BLIP-2 λ¨λΈ ν…μ¤νΈ (Carla μ΄λ―Έμ§€)
   - [ ] Zero-shot ν”„λ΅¬ν”„νΈ μµμ ν™”
   - [ ] λ‹¤μ–‘ν• μ£Όν–‰ μ‹λ‚λ¦¬μ¤ ν…μ¤νΈ

2. **λ‹¨κΈ° λ©ν‘**
   - [ ] λ¨λΈ κµ¬μ΅° μ§μ ‘ μμ •
     - Vision Encoder κµμ²΄ μ‹¤ν—
     - Q-Former μ»¤μ¤ν„°λ§μ΄μ§•
     - Projector λ μ΄μ–΄ μ¶”κ°€
   
3. **μ¤‘κΈ° λ©ν‘**
   - [ ] νμΈνλ‹ μ¤€λΉ„
     - κ³µκ° μμ¨μ£Όν–‰ λ°μ΄ν„°μ…‹ μ‹¤ν— (BDD100K, KITTI)
     - LoRA/PEFT ν™κ²½ κµ¬μ¶•
     - Carla λ°μ΄ν„° μμ§‘ νμ΄ν”„λΌμΈ
   - [ ] λ¨λΈ νμΈνλ‹ (Carla νΉν™”)

4. **μ¥κΈ° λ©ν‘**
   - [ ] μ¶λ ¥ κµ¬μ΅°ν™” (ν€μ›κ³Ό ν‘μ)
   - [ ] κ°•ν™”ν•™μµ μ—μ΄μ „νΈ μ—°λ™
   - [ ] ROS ν†µν•©

## π® μ‚¬μ© λ°©λ²•

### μ„¤μΉ
```bash
# κ°€μƒν™κ²½ ν™μ„±ν™”
source venv/bin/activate

# ν¨ν‚¤μ§€ μ„¤μΉ
pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu116
```

### μ‹¤ν–‰
```bash
# BLIP-2 λ¨λΈ ν…μ¤νΈ (Carla μ΄λ―Έμ§€)
python test_carla_image.py

# λ”λ―Έ μ΄λ―Έμ§€ ν…μ¤νΈ
python test_vision_llm.py

# BLIP-2 λ¨λΈ μ§μ ‘ μ‚¬μ©
python blip2_model.py
```

### Git ν‘Έμ‹
```bash
# λ³€κ²½μ‚¬ν•­ μλ™ μ»¤λ°‹ & ν‘Έμ‹
./git_push.sh "μ»¤λ°‹ λ©”μ‹μ§€"
```

## π“ λ¨λΈ λΉ„κµ

| λ¨λΈ | ν¬κΈ° | μƒνƒ | μ©λ„ |
|------|------|------|------|
| CLIP + GPT-2 | ~650MB | Projector λ―Έν•™μµ | κµ¬μ΅° ν•™μµμ© |
| BLIP-2 (opt-2.7b) | ~10GB | μ‚¬μ „ ν•™μµ μ™„λ£ | λ©”μΈ λ¨λΈ |

## π”§ κΈ°μ  μ¤νƒ

- **Vision Encoder**: CLIP ViT / BLIP-2 ViT-L
- **Language Model**: GPT-2 / OPT-2.7B
- **Framework**: PyTorch, Transformers
- **Simulation**: Carla (μμ •)
- **Integration**: ROS (μμ •)

## π’΅ ν•µμ‹¬ μ•„μ΄λ””μ–΄

1. **κ²½λ‰ν™” μ°μ„ **: Python 3.8 νΈν™, μµμ† μμ΅΄μ„±
2. **λ¨λ“ν™”**: Vision/Language μ»΄ν¬λ„νΈ λ¶„λ¦¬
3. **μ μ§„μ  κ°μ„ **: 
   - Zero-shot β†’ Prompt Engineering β†’ Fine-tuning
4. **μ‹¤ν— μ¤‘μ‹¬**: κµ¬μ΅° μμ • λ° λ‹¤μ–‘ν• μ‹λ„

## π› ν•΄κ²°λ λ¬Έμ 

### Python λ²„μ „ μ¶©λ
- **λ¬Έμ **: μµμ‹  PyTorch(2.4.1)μ μμ΅΄μ„±μ΄ Python 3.9+ μ”κµ¬
- **ν•΄κ²°**: PyTorch 1.12.1λ΅ λ‹¤μ΄κ·Έλ μ΄λ“ (Python 3.8 νΈν™)
- **κµν›**: Carla/ROS ν™κ²½μ—μ„λ” ν¨ν‚¤μ§€ λ²„μ „ νΈν™μ„± μ¤‘μ”

### μμ΅΄μ„± λ¬Έμ 
- sympy, typing-extensions, filelock λ“± λ²„μ „ μ¶©λ
- PyTorch λ²„μ „ μ΅°μ •μΌλ΅ μΌκ΄„ ν•΄κ²°

## π“ μ°Έκ³  μλ£

- [BLIP-2 λ…Όλ¬Έ](https://arxiv.org/abs/2301.12597)
- [Hugging Face BLIP-2](https://huggingface.co/docs/transformers/model_doc/blip-2)
- [Carla μ‹λ®¬λ μ΄ν„°](https://carla.org/)

## π‘¥ ν‘μ—…

- μ¶λ ¥ κµ¬μ΅°ν™”: ν€μ›κ³Ό μΈν„°νμ΄μ¤ ν‘μ ν•„μ”
- κ°•ν™”ν•™μµ μ—°λ™: μ¶”ν›„ ν†µν•© μμ •

## π“ λ©”λ¨

- BLIP-2 λ¨λΈ λ‹¤μ΄λ΅λ“ μ‹κ°„: μΈν„°λ„· μ†λ„μ— λ”°λΌ 15λ¶„-1μ‹κ°„
- GPU λ©”λ¨λ¦¬: μµμ† 8GB κ¶μ¥ (float16 μ‚¬μ©)
- CPU λ¨λ“λ„ μ§€μ›ν•μ§€λ§ λλ¦Ό

---

**Last Updated**: 2025λ…„ 11μ›” 8μΌ  
**Status**: π΅ κ°λ° μ§„ν–‰ μ¤‘
